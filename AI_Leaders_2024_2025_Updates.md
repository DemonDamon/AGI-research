# AI é¢†å†›äººç‰© 2024-2025 å¹´åº¦è§‚å¯ŸæŠ¥å‘Š

æœ¬æŠ¥å‘Šç³»ç»Ÿæ€§åœ°æœé›†äº† 20 ä½ AI é¢†åŸŸé¡¶çº§ç§‘å­¦å®¶ã€åˆ›ä¸šè€…åœ¨ 2024-2025 å¹´çš„é‡è¦è¨€è®ºã€å­¦æœ¯è®ºæ–‡ã€åšå®¢æ–‡ç« å’Œè®¿è°ˆï¼Œå±•ç°äº† AGI ç ”ç©¶ä¸äº§ä¸šçš„æœ€æ–°åŠ¨æ€ã€‚

## ç›®å½•

1. [Ilya Sutskever](#ilya-sutskever)
2. [Mira Murati](#mira-murati)
3. [John Schulman](#john-schulman)
4. [Barret Zoph](#barret-zoph)
5. [Dario Amodei](#dario-amodei)
6. [Daniela Amodei](#daniela-amodei)
7. [Andrej Karpathy](#andrej-karpathy)
8. [Pieter Abbeel](#pieter-abbeel)
9. [Peter Chen](#peter-chen)
10. [Rocky Duan](#rocky-duan)
11. [Aravind Srinivas](#aravind-srinivas)
12. [Kyle Kosic](#kyle-kosic)
13. [Emmett Shear](#emmett-shear)
14. [David Luan](#david-luan)
15. [Tim Shi](#tim-shi)
16. [Maddie Hall](#maddie-hall)
17. [Shariq Hashme](#shariq-hashme)
18. [Jonas Schneider](#jonas-schneider)
19. [Jeff Arnold](#jeff-arnold)
20. [Margaret Jennings](#margaret-jennings)

---

## Ilya Sutskever

**æ‰€å±æœºæ„**: Safe Superintelligence

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "After almost a decade, I have made the decision to leave OpenAI. The company's trajectory has been nothing short of miraculous, and I'm confident that OpenAI will build AGI that is both safe and beneficial under the leadership of @sama, @gdb, @miramurati and now, under the excellent leadership of @sama and @gdb. I am excited for what comes next â€” a project that is very personally meaningful to me on a technical level."
    *   **Source:** X (formerly Twitter) post (@ilyasut)
    *   **Date:** May 14, 2024
    *   **Context:** Announcement of his departure from OpenAI.

*   **Quote:** "Superintelligence is within reach. Building safe superintelligence (SSI) is the most important technical problem of our time."
    *   **Source:** SSI Inc. Launch Announcement (via X post)
    *   **Date:** June 19, 2024
    *   **Context:** Statement on the founding of Safe Superintelligence Inc.

*   **Quote:** "We plan to advance capabilities as fast as possible while making sure our safety always remains ahead. This way, we can scale in peace."
    *   **Source:** SSI Inc. Launch Announcement (via X post)
    *   **Date:** June 19, 2024
    *   **Context:** Describing SSI's core philosophy of co-developing safety and capability.

*   **Quote:** "We have the compute, we have the team, and we know what to do. Together we will keep building safe superintelligence."
    *   **Source:** SSI.inc Update (Internal message to team/investors)
    *   **Date:** July 3, 2025
    *   **Context:** Reaffirming commitment to the mission after taking over as CEO.

*   **Quote:** "We're moving from the age of scaling to the age of research."
    *   **Source:** Dwarkesh Podcast Interview (Title and core theme)
    *   **Date:** November 25, 2025
    *   **Context:** Highlighting the shift in AI development from simple model scaling to the need for fundamental breakthroughs.

*   **Quote:** "These models somehow just generalize dramatically worse than people. Itâ€™s a very fundamental thing."
    *   **Source:** Dwarkesh Podcast Interview
    *   **Date:** November 25, 2025
    *   **Context:** Discussing the disconnect between high evaluation scores and poor real-world performance in current large language models.

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Scaling and evaluating sparse autoencoders
    *   **Link:** https://arxiv.org/abs/2406.04093
    *   **Abstract:** Sparse autoencoders provide a promising unsupervised approach for extracting interpretable features from a language model by reconstructing activations from a sparse bottleneck layer. The paper proposes using k-sparse autoencoders to directly control sparsity, simplifying tuning and improving the reconstruction-sparsity frontier. It finds clean scaling laws and introduces new metrics for evaluating feature quality, demonstrating scalability by training a 16 million latent autoencoder on GPT-4 activations for 40 billion tokens.
    *   **Date:** June 6, 2024 (arXiv v1)
    *   **Authors:** Leo Gao, Tom DuprÃ© la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, **Ilya Sutskever**, Jeffrey Wu.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Safe Superintelligence Inc. Launch Announcement**
    *   **Link:** https://x.com/ssi/status/1803472825476587910 (via SSI Inc. X post, co-signed by Sutskever)
    *   **Summary:** The announcement details the founding of Safe Superintelligence Inc. (SSI) in June 2024. It states the company's singular focus is to build a safe superintelligence, treating safety and capabilities as technical problems to be solved in tandem, with safety always remaining ahead. The business model is designed to insulate the company from short-term commercial pressures.
    *   **Date:** June 19, 2024

*   **SSI Funding Announcement**
    *   **Link:** https://ssi.inc/updates
    *   **Summary:** Announcement of a significant funding round, raising $1 billion from NFDG, a16z, Sequoia, DST Global, and SV Angel.
    *   **Date:** September 4, 2024

*   **Ilya Sutskever formally takes over as CEO of SSI**
    *   **Link:** https://ssi.inc/updates
    *   **Summary:** Sutskever announces he is formally taking over as CEO following the departure of co-founder Daniel Gross. He reaffirms the company's commitment to its mission and dismisses acquisition rumors.
    *   **Date:** July 3, 2025

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Ilya Sutskever â€“ We're moving from the age of scaling to the age of research**
    *   **Link:** https://www.dwarkesh.com/p/ilya-sutskever-2
    *   **Key Points:** Sutskever discusses SSI's strategy, the limitations of current AI models' generalization, and the end of the "age of scaling," arguing that fundamental research is now the bottleneck. He states, "We are squarely an age of research company."
    *   **Date:** November 25, 2025

*   **NeurIPS 2024 Talk: "Pre-training as we know it will end"**
    *   **Link:** https://www.youtube.com/watch?v=sJE8qZmQWGU (YouTube link to the talk)
    *   **Key Points:** Sutskever's central thesis is that the current paradigm of pre-training on vast datasets is unsustainable because the supply of high-quality data is finite. He suggests the next phase of AI development will require new methodologies to achieve superintelligence, which he describes as "agentic, reasons, understands and is self-improving."
    *   **Date:** December 15, 2024 (Approximate date of the talk at NeurIPS 2024)

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Ilya Sutskever's impact in 2024-2025 is primarily defined by his departure from OpenAI and the founding of Safe Superintelligence Inc. (SSI).
*   **SSI Launch:** The launch of SSI in June 2024, with a singular focus on "safe superintelligence," generated massive media coverage across technology and business news outlets.
*   **Funding:** The announcement of a **$1 billion** funding round in September 2024 underscored the significant financial and industry confidence in his new venture.
*   **Social Media:** His May 14, 2024, farewell post on X received over **25K likes** and **3.5K reposts**, with over **5.8 million views**, indicating high engagement around his departure from OpenAI. The SSI launch post in June 2024 received over **14K likes** and **4.6K reposts**, with over **7.3 million views**, demonstrating the immediate and sustained interest in his new direction.
*   **Academic:** His co-authored paper, *Scaling and evaluating sparse autoencoders*, has been cited over **343 times** (as of November 2025), reflecting its immediate relevance in the field of AI interpretability.

---

## Mira Murati

**æ‰€å±æœºæ„**: Thinking Machines Lab

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "Right now, it feels quite achievable... Current evidence shows that progress will likely continue. Thereâ€™s not a lot of evidence to the contrary. Whether we need new ideas to get to AGI-level systems, thatâ€™s uncertain. Iâ€™m quite optimistic that the progress will continue."
    *   **Source:** WIRED's The Big Interview event
    *   **Date:** December 3, 2024
*   **Quote:** "I very quickly believed that AGI would be the last and most important major technology that we built, and I wanted to be at the heart of it."
    *   **Source:** Business Insider interview
    *   **Date:** April 23, 2025
*   **Quote:** "Our goal is simple, advance AI by making it broadly useful and understandable through solid foundations, open science, and practical applications."
    *   **Source:** Mira Murati's X/Twitter account (Announcing Thinking Machines Lab)
    *   **Date:** September 2024 (Approximate, based on search results)
*   **Quote:** "This technology is not intrinsically good or bad. It comes with both sides."
    *   **Source:** WIRED's The Big Interview event
    *   **Date:** December 3, 2024

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Thinking Machines Lab: The Polymath Cannot Be Purchased
*   **Link:** https://www.researchgate.net/publication/393777880_Thinking_Machines_Lab_The_Polymath_Cannot_Be_Purchased
*   **Abstract:** This paper, published in July 2025, is a commentary/analysis on the founding and mission of Thinking Machines Lab by an external researcher (DC Youvan). It explores the lab's rapid rise and its focus on the evolution of AI, framing the question of whether the kind of "polymath" AI the lab aims for can be achieved. *Note: This is a paper about the lab, not a technical paper authored by Murati or the lab's core team.*

*   **Title:** Thinking Machines: A Survey of LLM based Reasoning Strategies
*   **Link:** https://www.researchgate.net/publication/389894006_Thinking_Machines_A_Survey_of_LLM_based_Reasoning_Strategies
*   **Abstract:** Published in March 2025, this survey paper discusses reasoning strategies in Large Language Models (LLMs), including the concept of a "world model" as a feedback mechanism for tree-search. The title's use of "Thinking Machines" is a general reference to AI, and the paper is not directly authored by Mira Murati or her lab, but is relevant to the topics of her new company.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Title:** LoRA Without Regret
*   **Link:** https://thinkingmachines.ai/blog/lora/
*   **Summary:** A technical post from Thinking Machines Lab, published on September 29, 2025, detailing experiments on Low-Rank Adaptation (LoRA) for fine-tuning large language models. The post, authored by John Schulman and others, concludes that LoRA can match the performance of full fine-tuning under certain conditions, which they term the "low-regret regime," covering most post-training scenarios. The work emphasizes the efficiency and accessibility of LoRA for customizing models.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** Mira Murati Quit OpenAI. Sheâ€™s as Optimistic as Ever About AGI
*   **Link:** https://www.wired.com/story/big-interview-mira-murati-2024/
*   **Key Points:** Interview at WIRED's The Big Interview event on December 3, 2024. Murati expressed strong optimism about the continued progress toward AGI, stating, "Right now, it feels quite achievable." She also discussed her departure from OpenAI, calling the focus on employee exits "too much obsession," and highlighted the importance of synthetic data and computing infrastructure for future AI breakthroughs.

*   **Title:** Meet Mira Murati, Ex-OpenAI CTO Building AI Startup
*   **Link:** https://www.businessinsider.com/mira-murati-openai-startup-2025-4
*   **Key Points:** Interview published April 23, 2025, where Murati reiterated her long-standing belief in AGI, stating, "I very quickly believed that AGI would be the last and most important major technology that we built, and I wanted to be at the heart of it." The interview focused on the early stages and mission of Thinking Machines Lab.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Mira Murati's impact in 2024-2025 is primarily measured by the significant financial and media attention surrounding her new venture, Thinking Machines Lab.
*   **Funding:** The company raised a reported $2 billion seed round in mid-2025, valuing the startup at approximately $12 billion, a record for a seed-stage AI company.
*   **Media Coverage:** High-profile interviews (e.g., WIRED) and extensive news coverage of her departure from OpenAI (September 2024) and the launch of Thinking Machines Lab (February 2025) demonstrate continued high public interest and influence in the AI sector.
*   **Academic Recognition:** Awarded an honorary Doctor of Science degree from Dartmouth College in June 2024, recognizing her contributions to AI.

---

## John Schulman

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "OpenAI's John Schulman says artificial general intelligence could be two to three years away."
    *   **Source:** Business Insider, reporting on the Dwarkesh Podcast interview.
    *   **Date:** May 21, 2024
    *   **Link:** https://www.businessinsider.com/openai-cofounder-agi-coming-fast-needs-limits-john-schulman-2024-5

*   **Quote:** "Everyone needs to agree on some reasonable limits to deployment or to further training, for this to work. Otherwise, you have the race dynamics where everyone's trying to stay ahead, and that might require compromising on safety."
    *   **Source:** Business Insider, reporting on the Dwarkesh Podcast interview.
    *   **Date:** May 21, 2024
    *   **Link:** https://www.businessinsider.com/openai-cofounder-agi-coming-fast-needs-limits-john-schulman-2024-5

*   **Quote:** "Confirming that I left Anthropic last week. Leaving wasn't easy because I enjoyed the stimulating research environment and the kind and talented people I was working with, but I decided to go with another opportunity that I found extremely compelling. I'll share more details in the coming weeks. Thanks to Jared, Jan, Dario and others for the support during my time at Anthropic, and I wish them all the best."
    *   **Source:** X (formerly Twitter)
    *   **Date:** Feb 7, 2025
    *   **Link:** https://x.com/johnschulman2/status/1887724101667856725?lang=en

*   **Quote:** "Excited to build a new AI research lab with some of my favorite former colleagues and some great new ones. Looking forward to sharing more in the coming weeks." (This post was a retweet of the official Thinking Machines Lab announcement).
    *   **Source:** X (formerly Twitter)
    *   **Date:** Feb 18, 2025
    *   **Link:** https://x.com/johnschulman2/status/1891924467711926531

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Stress-Testing Model Specs Reveals Character Differences among Language Models
    *   **Link:** https://arxiv.org/abs/2510.07686
    *   **Date:** Oct 9, 2025 (v1 submission)
    *   **Abstract:** The paper presents a systematic methodology for stress-testing AI constitutions and model specifications to identify internal conflicts and insufficient coverage of nuanced scenarios. By generating value tradeoff scenarios, the authors evaluate twelve frontier LLMs and find significant behavioral divergence, which strongly predicts underlying problems in model specifications. The work also reveals clear misalignment cases and false-positive refusals across the models studied.

*   **Title:** Detecting Adversarial Fine-tuning with Auditing Agents
    *   **Link:** https://arxiv.org/abs/2510.16255
    *   **Date:** Oct 17, 2025 (v1 submission)
    *   **Abstract:** This work studies robust detection mechanisms for adversarial use of fine-tuning APIs, which can bypass safeguards in Large Language Models (LLMs). The authors introduce the concept of a fine-tuning auditing agent that can detect harmful fine-tuning prior to model deployment. Evaluating the approach on a diverse set of strong fine-tuning attacks, the auditing agent achieves a 56.2% detection rate at a 1% false positive rate, demonstrating its ability to detect covert attacks that evade safety evaluations.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Title:** LoRA Without Regret
    *   **Link:** https://thinkingmachines.ai/blog/lora/
    *   **Date:** Sep 29, 2025
    *   **Summary:** A technical blog post co-authored by John Schulman and others at Thinking Machines Lab. The post characterizes a "low-regret regime" where Low-Rank Adaptation (LoRA) performs similarly to Full Fine-Tuning (FullFT) in terms of dataset size and LoRA parameters. The finding suggests that this regime covers most post-training scenarios, enabling the use of efficient fine-tuning in many applications.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** John Schulman (OpenAI Cofounder) - Reasoning, RLHF, & Plan for 2027 AGI
    *   **Link:** https://www.dwarkesh.com/p/john-schulman
    *   **Date:** May 15, 2024
    *   **Key Points:**
        *   **AGI Timeline:** Predicted that AGI could be achieved in "two or three years" (i.e., 2026-2027).
        *   **Model Capabilities:** Predicted that in one or two years, models will be able to carry out complex, multi-step tasks like a whole coding project, iterating on high-level instructions.
        *   **Post-training/RLHF:** Discussed how post-training (including RLHF) is a complex operation requiring tacit and organizational knowledge, creating a "moat" for companies like OpenAI.
        *   **Generalization:** Noted that a tiny amount of data (e.g., 30 examples) can generalize well to fix issues like models overstating their capabilities (e.g., claiming they can send an email).
        *   **Web Interaction:** Suggested that models will be able to use human-designed websites using vision, but that AI-specific UXs might be beneficial for certain applications.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

John Schulman's public activity in 2024-2025 was marked by significant career transitions and high-impact research publications.

*   **Social Media Impact:** His X post on February 7, 2025, confirming his departure from Anthropic, garnered **444.8K Views**, **2.8K Likes**, and **102 Reposts**, indicating high public interest in his career moves. His post on February 18, 2025, announcing the new lab, received **112.9K Views**, **1.2K Likes**, and **52 Reposts**.
*   **Academic Impact:** The paper **"Stress-Testing Model Specs Reveals Character Differences among Language Models"** (arXiv:2510.07686) was submitted in October 2025 and has already been cited by other works in the field. The paper **"Detecting Adversarial Fine-tuning with Auditing Agents"** (arXiv:2510.16255) was also submitted in October 2025, contributing to the critical area of LLM safety and security.
*   **Media Coverage:** His interview on the Dwarkesh Podcast in May 2024 was widely covered by major news outlets like Business Insider, highlighting the continued relevance of his views on AGI timelines and safety.

---

## Barret Zoph

### ğŸ“¢ é‡è¦è¨€è®º

*   **Statement:** "Thinking Machines Lab exists to empower humanity through advancing **collaborative general intelligence**. We're building multimodal AI that works with how you think, not against it."
    *   **Source:** X post by @barret_zoph
    *   **Date:** September 26, 2024
    *   **Context:** Announcing the mission and focus of the newly formed Thinking Machines Lab, where Zoph is CTO.

*   **Statement:** "I posted a few weeks ago about the launch of Thinking Machines Lab. We're building a new kind of AI, focused on **collaborative general intelligence**."
    *   **Source:** X post by @barret_zoph
    *   **Date:** September 26, 2024 (The post text refers to a previous post, but this is the most recent post available in the feed, which is likely the main announcement post.)
    *   **Context:** Follow-up on the company's launch and reiteration of the core AI concept.

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Scaling Instruction-Finetuned Language Models
    *   **Link:** `http://www.jmlr.org/papers/v25/23-0870.html`
    *   **Abstract:** "Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation, RealToxicityPrompts). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PaLM 540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks (at time of release), such as 75.2% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models."
    *   **Date:** 2024

### ğŸ“ åšå®¢æ–‡ç« 

*   **Thinking Machines Lab Launch Announcement**
    *   **Link:** The initial announcement was widely covered by tech news outlets on February 18, 2025, and was likely accompanied by a blog post on the company's site, though a direct link to a post authored by Zoph is not available. The core message is reflected in the company's mission statement.
    *   **Summary:** Barret Zoph was announced as the CTO and Co-Founder of Thinking Machines Lab in February 2025, a new AI startup founded by former OpenAI CTO Mira Murati. The company's focus is on "collaborative general intelligence" and building multimodal AI.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Thinking Machines Lab Mission Statement**
    *   **Link:** `https://x.com/barret_zoph/status/1945229617885012103` (Barret Zoph's X post, Sep 26, 2024)
    *   **Key Points:** This post, which appears to be a key statement from the company's launch, states the mission: "Thinking Machines Lab exists to empower humanity through advancing **collaborative general intelligence**. We're building multimodal AI that works with how you think, not against it." This is the primary public-facing statement from Zoph in his new role.
*   **Other Interviews/Talks:** No other specific, named interviews or talks from 2024-2025 were found in the search results. The primary public communication is through the company's mission statement.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

*   **Academic Impact:** The paper "Scaling Instruction-Finetuned Language Models" (2024) has been cited over 5082 times (as of the initial search), indicating a high level of influence in the field of large language model research.
*   **Social Media/Startup Impact:** Barret Zoph's X account has 22.6K followers. The announcement of Thinking Machines Lab, where he is CTO, generated significant media coverage in early 2025, with the company reaching a valuation of up to $12 billion in a seed round by July 2025, demonstrating substantial industry and investor interest. The X post announcing the company's mission had 3.4K likes, 308 reposts, and over 1 million views.

---

## Dario Amodei

### ğŸ“¢ é‡è¦è¨€è®º

- **Quote:** "I think that most people are underestimating just how radical the upside of AI could be, just as I think most people are underestimating how bad the risks could be."
  - **Source:** Machines of Loving Grace: How AI Could Transform the World for the Better (Essay)
  - **Date:** October 2024
  - **Link:** <https://www.darioamodei.com/essay/machines-of-loving-grace>
- **Quote:** "My basic prediction is that AI-enabled biology and medicine will allow us to compress the progress that human biologists would have achieved over the next 50-100 years into 5-10 years."
  - **Source:** Machines of Loving Grace: How AI Could Transform the World for the Better (Essay)
  - **Date:** October 2024
  - **Link:** <https://www.darioamodei.com/essay/machines-of-loving-grace>
- **Quote:** "I think there's a 25% chance that things go really, really badly."
  - **Source:** Axios AI+ DC Summit
  - **Date:** September 17, 2025
  - **Link:** <https://www.axios.com/2025/09/17/anthropic-dario-amodei-p-doom-25-percent>
- **Quote:** "AI could wipe out half of all entry-level white-collar jobs â€” and spike unemployment to 10-20% in the next one to five years."
  - **Source:** Axios Interview / CBS 60 Minutes
  - **Date:** May 28, 2025 / November 16, 2025
  - **Link:** <https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic>
- **Quote:** "We are the only frontier AI company to restrict the selling of AI services to PRC-controlled companies, forgoing significant short-term revenue to prevent fueling AI platforms and applications that would help the Chinese Communist Party's military and intelligence services."
  - **Source:** A statement from Dario Amodei on Anthropic's commitment to American AI leadership (Anthropic News)
  - **Date:** October 21, 2025
  - **Link:** <https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership>

### ğŸ“„ å­¦æœ¯è®ºæ–‡

- **Title:** [Which Economic Tasks are Performed with AI? Evidence from Millions of Claude Conversations](https://arxiv.org/abs/2503.04761)
  - **Date:** February 11, 2025
  - **Abstract:** Despite widespread speculation about artificial intelligence's impact on the future of work, we lack systematic empirical evidence about how these systems are actually being used for different tasks. Here, we present a novel framework for measuring AI usage patterns across the economy. We leverage a recent privacy-preserving system to analyze over four million Claude.ai conversations through the lens of tasks and occupations in the U.S. Department of Labor's O*NET Database. Our analysis reveals that AI usage primarily concentrates in software development and writing tasks, which together account for nearly half of all total usage. However, usage of AI extends more broadly across the economy, with approximately 36% of occupations using AI for at least a quarter of their associated tasks. We also analyze how AI is being used for tasks, finding 57% of usage suggests augmentation of human capabilities (e.g., learning or iterating on an output) while 43% suggests automation (e.g., fulfilling a request with minimal human involvement). While our data and methods face important limitations and only paint a picture of AI usage on a single platform, they provide an automated, granular approach for tracking AI's evolving role in the economy and identifying leading indicators of future impact as these technologies continue to advance.

### ğŸ“ åšå®¢æ–‡ç« 

- **Title:** [Machines of Loving Grace: How AI Could Transform the World for the Better](https://www.darioamodei.com/essay/machines-of-loving-grace)
  - **Date:** October 2024
  - **Summary:** A comprehensive, 15,000-word essay outlining an optimistic vision for the future of AI, focusing on the potential for radical upside in areas like biology, medicine, neuroscience, economic development, and governance. Amodei argues that AI could 'compress the progress that human biologists would have achieved over the next 50-100 years into 5-10 years' and emphasizes the need to focus on AI safety to realize this positive future.
- **Title:** [A statement from Dario Amodei on Anthropic's commitment to American AI leadership](https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership)
  - **Date:** October 21, 2025
  - **Summary:** A public statement reaffirming Anthropic's commitment to advancing American AI leadership. Amodei addresses recent inaccurate claims about the company's policy stances, highlights their work with the federal government (including the Department of War and GSA), and defends their policy positions, such as supporting a national AI standard and restricting the sale of AI services to PRC-controlled companies.
- **Title:** [Anthropic Economic Index report: Uneven geographic and enterprise AI adoption](https://www.anthropic.com/research/anthropic-economic-index-september-2025-report)
  - **Date:** September 15, 2025
  - **Summary:** A research report extending the Anthropic Economic Index to include geographic analysis of Claude.ai conversations, revealing uneven AI adoption patterns across different regions and enterprises. The report is co-authored by Dario Amodei and others, providing data-driven insights into the evolving economic impact of AI.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

- **Title:** [Axios AI+ DC Summit](https://www.axios.com/2025/09/17/anthropic-dario-amodei-p-doom-25-percent)
  - **Date:** September 17, 2025
  - **Key Points:**
    - Stated a '25% chance that things go really, really badly' with AI, referring to the probability of catastrophic outcomes (p-doom).
    - Discussed the need for robust safety measures and governance to mitigate extreme risks.
- **Title:** [Interview on AI Job Impact (Axios)](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic)
  - **Date:** May 28, 2025
  - **Key Points:**
    - Predicted that AI could eliminate half of all entry-level white-collar jobs within the next one to five years.
    - Warned that this could lead to a spike in unemployment to 10-20%.
- **Title:** [60 Minutes Interview (CBS News)](https://www.cbsnews.com/news/anthropic-ceo-dario-amodei-warning-of-ai-potential-dangers-60-minutes-transcript/)
  - **Date:** November 16, 2025
  - **Key Points:**
    - Reiterated the warning that AI could wipe out half of all entry-level white-collar jobs and spike unemployment to 10% to 20%.
    - Emphasized the need for caution and guardrails on AI development, noting that the job impact will be 'faster than what we've seen before'.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

**Papers:** The paper 'Which Economic Tasks are Performed with AI?' (arXiv:2503.04761) was cited at least 73 times by November 2025, indicating significant academic and industry attention to Anthropic's economic analysis of AI usage.

**Statements:** The '25% chance of things going really, really badly' statement from the Axios AI+ DC Summit (Sep 2025) was widely reported by major news outlets (TechRadar, Yahoo News, etc.), generating significant discussion on social media and in the press regarding AI existential risk.

**Blog Posts:** The essay 'Machines of Loving Grace' (Oct 2024) was a major event in the AI community, prompting numerous summaries, reviews, and discussions on platforms like LessWrong, Reddit, and various newsletters, demonstrating high engagement and influence on the discourse about AI's long-term potential.

---

## Daniela Amodei

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "AI is this incredible force multiplier that helps you to think â€˜What are the things I really want to develop and build?â€™"
    *   **Source:** Canva Create Address, as reported by Variety
    *   **Date:** April 11, 2025
*   **Quote:** "Weâ€™re thinking very critically about how access to this technology is really available to people reagardless of where they are in the world. Without active efforts we worry that AI will be concentrated in the particular places that all technological breakthroughs have been."
    *   **Source:** Canva Create Address, as reported by Variety
    *   **Date:** April 11, 2025
*   **Quote:** "These models have this ability to ingest a huge amount of context and information... You could have this personalized tutor for life. This partner knows and understands you and has seen you grow potentially from a young age."
    *   **Source:** Canva Create Address, as reported by Variety
    *   **Date:** April 11, 2025
*   **Quote:** Anthropic was "founded on this belief that you can develop transformative AI technologies in way that is good and safe and beneficial for everyone."
    *   **Source:** Canva Create Address, as reported by Variety
    *   **Date:** April 11, 2025

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** None found with Daniela Amodei as a named author in 2024-2025.
*   **Summary:** While Anthropic researchers published several high-profile papers in 2024-2025 (e.g., "Values in the Wild," "Alignment Faking in Large Language Models"), Daniela Amodei was not listed as an author on the publicly available preprints or final versions. Her role as President is executive, focusing on policy, safety, and business strategy rather than direct academic research authorship.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Title:** None found with Daniela Amodei as a named author in 2024-2025.
*   **Summary:** Search results did not identify any company blog posts or articles primarily authored by Daniela Amodei in the 2024-2025 period. Anthropic's "essay culture" was mentioned, but the most prominent essay, "Machines of Loving Grace," was authored by her brother, Dario Amodei.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** Anthropic Chief: AI Tools Will Be 'Force Multiplier' for Business (Canva Create Address)
    *   **Link:** https://variety.com/2025/biz/news/anthropic-daniela-amodei-chief-ai-force-multiplier-1236367447/
    *   **Date:** April 11, 2025
    *   **Key Points:**
        *   AI tools will become a **"force multiplier"** for businesses, sparking productivity gains similar to those in the 1980s and '90s.
        *   Stressed the need for **ethical and security guardrails** to be built into AI tools.
        *   Emphasized the importance of **global access** to AI technology to prevent concentration of benefits: "Without active efforts we worry that AI will be concentrated in the particular places that all technological breakthroughs have been."
        *   Described the potential of an AI agent like Claude to become a **"personalized tutor for life"** that "knows and understands you and has seen you grow potentially from a young age."
        *   Noted that for businesses, **"the majority of AI use cases are augmentative,"** helping humans with creative work in particular.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Daniela Amodei's influence is primarily reflected in her executive role as President of Anthropic, a company valued at over $61 billion in 2025.
*   **Media Recognition:** Included in Fortune's list of the Most Powerful Women in 2024, with some rankings placing her at #1 in 2025.
*   **Corporate Growth:** Anthropic grew from 300 to 1,000 employees in the year leading up to April 2025, a period of significant growth she oversaw.
*   **Product Reach:** The user base for Anthropic's Claude is reported to be "growing like crazy."
*   **Public Speaking:** Her address at Canva Create in April 2025 was covered by major industry publications like Variety, indicating significant media interest in her public statements.

---

## Andrej Karpathy

**æ‰€å±æœºæ„**: Eureka Labs

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "There's a new kind of coding I call 'vibe coding', where you fully give in to the vibes, embrace exponentials, and forget that the code even exists."
    *   **Source:** X/Twitter post (@karpathy)
    *   **Date:** February 2, 2025
*   **Quote:** "The former Tesla executive has said that it will take at least another ten years for any AI company or research lab to achieve AGI, a hypothetical level of intelligence that would enable an AI system to perform complex tasks at the same level or better than humans. One of the reasons for the decade-long wait is that no one has been able to develop an AI system that learns continually."
    *   **Source:** Dwarkesh Podcast / *The Indian Express* article summarizing the podcast
    *   **Date:** October 17, 2025 (Podcast release) / October 21, 2025 (Article)
*   **Quote:** "My most amusing interaction was where the model (I think I was given some earlier version with a stale system prompt) refused to believe me that it is 2025 and kept inventing reasons why I must be trying to trick it or playing some elaborate joke on it."
    *   **Source:** X/Twitter post (@karpathy) about an early access test of Gemini 3
    *   **Date:** November 18, 2025

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Vibe coding: programming through conversation with large language models
*   **Link:** https://arxiv.org/abs/2506.23253v1 (Karpathy is cited as the originator of the term, not an author)
*   **Abstract:** This paper, published in June 2025, is one of several academic works that emerged following Karpathy's coining of the term "vibe coding." It analyzes the concept, which describes a development style where programmers use conversational LLMs to generate code, often accepting the output without deep scrutiny. The paper investigates the motivations, challenges, and implications of this new programming paradigm. **Note:** Andrej Karpathy does not appear to have been a primary author on any new academic papers in 2024-2025, with his focus shifting to Eureka Labs and public commentary. His influence is seen through the academic study of his public concepts.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Title:** Introducing Eureka Labs
*   **Link:** https://eurekalabs.ai/
*   **Date:** July 16, 2024
*   **Summary:** Karpathy announced the launch of Eureka Labs, an "AI native" school. The post describes the vision of a Teacher + AI symbiosis to scale high-quality education, where the teacher designs the materials and an AI Teaching Assistant guides the students. The first product announced is an undergraduate-level AI course called LLM101n.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** Andrej Karpathy â€” AGI is still a decade away (Dwarkesh Podcast)
*   **Link:** https://www.dwarkesh.com/p/andrej-karpathy
*   **Date:** October 17, 2025
*   **Key Points:**
    *   **AGI Timeline:** Karpathy stated that AGI is still "a decade away," revising his previous, more optimistic timelines.
    *   **AI Agents:** He expressed skepticism about the immediate future of AI agents, stating that the "year of agents" (referring to 2025) is premature, and that current agents are "slop" because they lack the ability to learn continually.
    *   **Reinforcement Learning:** Discussed the inefficiencies of reinforcement learning, noting that while it is flawed, other current methods are "much worse."
    *   **Eureka Labs Vision:** Elaborated on the vision for Eureka Labs as an AI-native school, focusing on the Teacher + AI symbiosis model.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Andrej Karpathy's statements and activities in 2024-2025 generated significant engagement, particularly on social media and in the tech press.
*   **"Vibe Coding":** The term, coined on X/Twitter in February 2025, quickly gained traction, leading to multiple academic papers (e.g., *Vibe coding: programming through conversation with...* on arXiv) and articles in major tech publications, indicating high virality and influence on the developer community.
*   **AGI Timeline:** His October 2025 statement that AGI is "still a decade away" was widely reported by news outlets globally (e.g., *The Indian Express*, *TechCrunch*), sparking considerable debate and serving as a counter-narrative to more optimistic timelines from other industry leaders.
*   **Gemini 3 Interaction:** The anecdote about Gemini 3 refusing to believe it was 2025, shared on X/Twitter in November 2025, became a viral story, highlighting the real-world limitations of LLMs and generating numerous articles and discussions about model training and system prompts.
*   **Eureka Labs:** The launch of his new venture in July 2024 was covered by major tech news sites (e.g., *TechCrunch*), demonstrating his continued influence in the AI and education sectors.

---

## Pieter Abbeel

### ğŸ“¢ é‡è¦è¨€è®º

*   **"The Amazon AGI SF Lab will focus on developing new foundational capabilities for enabling useful AI agents that can take actions in the digital and physical worlds. In other words, weâ€™re enabling practical AI that can actually do things for us and make our customers more productive, empowered, and fulfilled."**
    *   **Source:** Amazon Science Blog Post: "Amazon opens new AI lab in San Francisco focused on long-term research bets" (Joint statement with David Luan)
    *   **Date:** December 9, 2024
*   **"Weâ€™re entering an exciting new era where AI agents are the next playing field; the right research bets can reinvent whatâ€™s possible with AI."**
    *   **Source:** Amazon Science Blog Post: "Amazon opens new AI lab in San Francisco focused on long-term research bets" (Joint statement with David Luan)
    *   **Date:** December 9, 2024
*   **"The missing piece is the brain, the AI to power all of it."**
    *   **Source:** NVIDIA GTC 2025 Talk: "AI for Humanoid Robots"
    *   **Date:** March 2025
*   **"The challenge is... how do we combine all these types of data to get what we want that is a robot capable of interacting with us, with objects in the world, and doing meaningful things? But it's not a simple recipe of just take a ton of text and do next token prediction."**
    *   **Source:** NVIDIA GTC 2025 Talk: "AI for Humanoid Robots"
    *   **Date:** March 2025

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Twisting Lids Off with Two Hands**
    *   **Link:** https://arxiv.org/abs/2403.02338
    *   **Abstract:** Manipulating objects with two multi-fingered hands is a long-standing challenge in robotics. This work shares novel insights into physical modeling, real-time perception, and reward design that enable policies trained in simulation using deep reinforcement learning (RL) to be effectively and efficiently transferred to the real world. The paper demonstrates policies with generalization capabilities across a diverse set of unseen objects, specifically for twisting lids off various bottle-like objects with two hands. (Presented at CoRL 2024)
*   **Semi-Supervised One-Shot Imitation Learning**
    *   **Link:** https://arxiv.org/abs/2408.05285
    *   **Abstract:** This paper introduces the problem setting of semi-supervised One-Shot Imitation Learning (OSIL), which is argued to be a more realistic setting for developing OSIL methods that can scale to real-world settings. The method leverages both a small set of labeled, high-quality demonstrations and a large set of unlabeled, low-quality demonstrations to improve performance and generalization.
*   **FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control**
    *   **Link:** https://arxiv.org/abs/2505.22642
    *   **Abstract:** Reinforcement learning (RL) complexity and long training times are major bottlenecks in robotics. This report introduces FastTD3, a simple, fast, and capable RL algorithm that significantly speeds up training for humanoid robots in popular suites. The method uses an off-policy TD3 agent with modifications like parallel simulation, large-batch updates, a distributional critic, and tuned hyperparameters, allowing it to solve a range of HumanoidBench tasks in under 3 hours on a single A100 GPU.
*   **DexterityGen: Foundation Controller for Unprecedented Dexterity**
    *   **Link:** https://arxiv.org/abs/2502.04307
    *   **Abstract:** This work introduces a foundation controller for dexterous manipulation, leveraging large-scale data and a novel training methodology to achieve unprecedented levels of dexterity and generalization across a wide range of complex, contact-rich tasks. The controller is designed to be a general-purpose "brain" for robot hands, capable of zero-shot transfer to new objects and tasks.

### ğŸ“ åšå®¢æ–‡ç« 

*   **Introducing the next phase of our AI Robotics journey**
    *   **Date:** August 30, 2024
    *   **Link:** https://covariant.ai/insights/introducing-the-next-phase-of-our-ai-robotics-journey/
    *   **Summary:** Covariant announced an agreement with Amazon, which includes a non-exclusive license to Covariantâ€™s Robotic Foundation Models for Amazon. Pieter Abbeel, Peter Chen, Rocky Duan, and other research and engineering team members joined Amazon. The post highlights the success of the "Covariant Brain" and its role in accelerating the deployment of AI Robotics. The remaining Covariant team, led by Ted Stinson (CEO) and Tianhao Zhang, will continue to focus on delivering the Covariant Brain to a broad set of global industries.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **AI for Humanoid Robots**
    *   **Date:** March 2025 (NVIDIA GTC 2025)
    *   **Link:** https://www.nvidia.com/en-us/on-demand/session/gtc25-s73182/
    *   **Key Points:**
        *   The hardware for humanoid robots is progressing rapidly, but the "missing piece is the brain, the AI to power all of it."
        *   The challenge is that, unlike LLMs with massive text data, there is no large, unified dataset for humanoid robots.
        *   The solution lies in combining multiple data sources: large-scale internet data for background knowledge, real-world and simulated reinforcement learning for interaction, and human-in-the-loop feedback (like RLHF) to align robot actions with human preferences.
        *   The talk emphasizes the need for a complex, multi-faceted research approach to solve the "complicated puzzle" of embodied AI.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Pieter Abbeel's work in 2024-2025 is marked by two major organizational and research shifts:
*   **Organizational Impact:** Transition from Covariant to Amazon, co-founding the **Amazon AGI SF Lab** (Dec 2024) as an Amazon Scholar for Robotics, signaling a major investment and focus on AGI and embodied AI agents within Amazon.
*   **Academic Impact:** The paper **"Twisting Lids Off with Two Hands"** (Mar 2024) has been cited **47 times** (as of Nov 2025), demonstrating significant and rapid influence in the field of robot learning and bimanual manipulation. The paper **"FastTD3"** (May 2025) has been cited **11 times** (as of Nov 2025), indicating early traction for its efficient RL algorithm for humanoid control.
*   **Public Reach:** The **NVIDIA GTC 2025** talk on "AI for Humanoid Robots" is a high-profile platform, reaching a wide audience of industry professionals and researchers.

---

## Peter Chen

**æ‰€å±æœºæ„**: Covariant

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "RFM-1 is basically a large language model (LLM), but for robot language."
    *   **Source:** TechCrunch Article: "Covariant is building ChatGPT for robots"
    *   **Date:** March 11, 2024
*   **Quote:** "The vision of RFM-1 is to power the billions of robots to come. We at Covariant have already deployed lots of robots at warehouses with success. But that is not the limit of where we want to get to. We really want to power robots in manufacturing, food processing, recycling, agriculture, the service industry and even into peopleâ€™s homes."
    *   **Source:** TechCrunch Article: "Covariant is building ChatGPT for robots"
    *   **Date:** March 11, 2024
*   **Quote:** "At Berkeley and OpenAI, we thought deeply about how to build a really general AI for robotics. And the thing that struck me was that 90% of tasks in the world were not even known in the academic community."
    *   **Source:** Covariant Blog Post: "Founderâ€™s perspective: Building a truly general AI for robotics must be done in the real world"
    *   **Date:** April 08, 2024
*   **Quote:** "Coupling the intelligence inflection point with the hardware inflection point is where we will see even more explosion of robot applications. But a lot of those are not fully there yet, especially on the hardware side. Itâ€™s very hard to go beyond the [staged video]. How many people have interacted with a humanoid in person? That tells you the degree of maturity."
    *   **Source:** TechCrunch Article: "Covariant is building ChatGPT for robots"
    *   **Date:** March 11, 2024

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **RFM-1: A Robotics Foundation Model**
    *   **Link:** https://covariant.ai/insights/rfm-1-a-world-model-that-understands-physics/ (Covariant's official announcement, no traditional academic paper found)
    *   **Abstract:** RFM-1 is Covariant's proprietary Robotics Foundation Model, a multimodal any-to-any sequence model trained on a massive dataset of real-world physical interactions (text, images, video, robot actions, and physical measurements). It is designed to give commercial robots the "human-like ability to reason" by simulating physical outcomes and determining the best course of action for complex tasks like bin picking, representing a major step towards generalized AI for robotics.
*   **Note on Academic Papers:** No traditional, peer-reviewed academic paper with Peter Chen as an author was found for the 2024-2025 period. The primary technical output is the commercial **RFM-1** model, which was announced via company blog posts and media coverage, not a formal academic publication. The closest equivalent is the detailed technical description provided in the Covariant blog posts.

### ğŸ“ åšå®¢æ–‡ç« 

*   **RFM-1: A world model that understands physics**
    *   **Link:** https://covariant.ai/insights/rfm-1-a-world-model-that-understands-physics/
    *   **Date:** March 11, 2024
    *   **Summary:** This post introduces RFM-1, Covariant's Robotics Foundation Model, which is trained on a massive multimodal dataset from real-world warehouse operations. The model is described as a "world model" that understands physics and can predict how robots will manipulate objects and interact with their surroundings, enabling human-like reasoning in commercial robots.
*   **Founderâ€™s perspective: Building a truly general AI for robotics must be done in the real world**
    *   **Link:** https://covariant.ai/insights/founder-s-perspective-building-a-truly-general-ai-for-robotics-must-be-done-in-the-real-world/
    *   **Date:** April 08, 2024
    *   **Summary:** Highlighting Peter Chen's panel at NVIDIA GTC 2024, this post argues that achieving truly general AI for robotics requires deploying systems in the complexities of real-world environments to gather the necessary diverse data, a point Chen emphasizes by stating that "90% of tasks in the world were not even known in the academic community."
*   **RFM-1 update: In-context learning to improve grasping**
    *   **Link:** https://covariant.ai/insights/rfm-1-update-in-context-learning-to-improve-grasping/
    *   **Date:** March 27, 2024
    *   **Summary:** This update details how RFM-1, a multimodal any-to-any sequence model, uses in-context learning to adapt and improve grasping performance in unexpected or new scenarios, further demonstrating its generalized intelligence capabilities.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **NVIDIA GTC Panel: Founderâ€™s perspective: Building a truly general AI for robotics must be done in the real world**
    *   **Link:** https://covariant.ai/insights/founder-s-perspective-building-a-truly-general-ai-for-robotics-must-be-done-in-the-real-world/
    *   **Date:** April 08, 2024
    *   **Key Points:** Chen discussed the necessity of real-world deployment for achieving general AI in robotics, stating that academic settings often miss the "90% of tasks" robots encounter in the field. He highlighted RFM-1 as the first commercial Robotics Foundation Model, trained on multimodal data including text, visuals, videos, and physical measurements.
*   **TechCrunch Article: Covariant is building ChatGPT for robots**
    *   **Link:** https://techcrunch.com/2024/03/11/covariant-is-building-chatgpt-for-robots/
    *   **Date:** March 11, 2024
    *   **Key Points:** This interview/feature provided a key quote from Chen describing RFM-1 as "basically a large language model (LLM), but for robot language." He outlined the vision for RFM-1 to power billions of robots across various sectors like manufacturing, food processing, and the service industry, and noted that the hardware for general-purpose robots (like humanoids) is "not fully there yet."
*   **What's Your Problem Podcast: Using AI to build better robots**
    *   **Link:** (Direct link not found, referenced on Covariant Insights page)
    *   **Date:** February 06, 2024
    *   **Key Points:** Chen discussed the problem of building generalized AI for robots, emphasizing the need for a foundation model approach to handle the variability and complexity of real-world tasks, moving beyond single-purpose, pre-programmed systems.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

The primary impact metric is the launch and adoption of **RFM-1 (Robotics Foundation Model 1)**, which was widely covered by major technology and industry publications (e.g., TechCrunch, The New York Times, IEEE Spectrum) in March 2024. This coverage positions Covariant and Peter Chen at the forefront of the "ChatGPT for robots" movement, signaling a significant shift in the approach to industrial robotics. The model's success is tied to its deployment in customer warehouses, with the company emphasizing the massive, real-world multimodal dataset it is built upon. The lack of publicly available, specific citation counts for the RFM-1 concept (as it was announced as a product/blog post, not a traditional academic paper) means impact is measured by media coverage and industry attention.

---

## Rocky Duan

### ğŸ“¢ é‡è¦è¨€è®º

*   **Statement:** "Yes, 2024 is shaping up a big year for robotics! ... No AGI for you in 2025."
    *   **Source:** Rocky Duan's Twitter/X account (@rocky_duan), quoted by Peter Chen (@peterxichen)
    *   **Date:** August 25, 2024
    *   **Context:** A statement reflecting optimism about the near-term progress in robotics while expressing skepticism about the immediate arrival of Artificial General Intelligence (AGI) in 2025.

*   **Statement:** "Excited to share that we're starting a [Frontier AI for Robotics] team."
    *   **Source:** Rocky Duan's LinkedIn Profile
    *   **Date:** September 2024
    *   **Context:** A statement made upon joining Amazon as a Senior Principal Applied Scientist and Research Lead for the newly formed Frontier AI for Robotics (FAR) team, following the acquisition of Covariant's core team.

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Sim-to-Real Learning for Humanoid Box Loco-Manipulation**
    *   **Link:** https://ieeexplore.ieee.org/abstract/document/10610977/
    *   **Date:** May 2024 (2024 IEEE International Conference on Robotics and Automation - ICRA 2024)
    *   **Abstract:** This work proposes a learning-based approach to box loco-manipulation for a humanoid robot, a challenging problem requiring whole-body coordination for lifting, carrying, and maintaining balance. The authors present a sim-to-real reinforcement learning approach to train general pickup and carrying skills for the bipedal robot Digit. The system combines learned skills to move boxes of various sizes and weights, demonstrating successful sim-to-real transfer on real-world hardware, marking a significant step in learned control for such tasks.

*   **TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**
    *   **Link:** https://arxiv.org/abs/2511.02832
    *   **Date:** November 2025 (arXiv)
    *   **Abstract:** Addressing the lack of effective data collection frameworks in humanoid robotics, this paper introduces TWIST2, a portable, mocap-free teleoperation and data collection system. It uses PICO4U VR for real-time whole-body human motion capture and a custom 2-DoF robot neck for egocentric vision, enabling holistic human-to-humanoid control. The system is shown to be highly efficient, collecting 100 demonstrations in 15 minutes with high success. The authors also propose a hierarchical visuomotor policy framework that autonomously controls the full humanoid body based on egocentric vision, successfully demonstrating dexterous manipulation and dynamic kicking tasks. The entire system and collected dataset are open-sourced.

### ğŸ“ åšå®¢æ–‡ç« 

*   **The Future of Robotics: Robotics Foundation Models and the role of data**
    *   **Link:** https://covariant.ai/insights/the-future-of-robotics-robotics-foundation-models-and-the-role-of-data/
    *   **Date:** January 08, 2024
    *   **Summary:** A foundational post discussing the creation of Covariant to build the first foundation model for robotics, highlighting the use of mixed data (general image/text and real-world/simulation warehouse data) to enable the "Covariant Brain" to see, think, and act, ultimately handling dull, dangerous, and repetitive tasks in warehouses.

*   **Introducing the next phase of our AI Robotics journey**
    *   **Link:** https://covariant.ai/insights/introducing-the-next-phase-of-our-ai-robotics-journey/
    *   **Date:** August 30, 2024
    *   **Summary:** The official announcement of the acquisition of Covariant's core team, including Rocky Duan, by Amazon, and the licensing of the Covariant Brain technology. This marks a significant transition in his career focus to Amazon's Frontier AI for Robotics (FAR) team.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **How the A.I. That Drives ChatGPT Will Move Into ...**
    *   **Source:** The New York Times (Article featuring Rocky Duan)
    *   **Link:** https://www.nytimes.com/2024/03/11/technology/ai-robots-technology.html
    *   **Date:** March 11, 2024
    *   **Key Points:** Featured as one of the three Covariant founders (CTO) in a major article discussing the application of large language model principles to robotics, specifically the "Covariant Brain" as a foundation model for robotics.

*   **The Robot Brains Podcast: From OpenAI to developing the first foundation models for robotics**
    *   **Source:** Covariant Website/Podcast Platforms
    *   **Link:** https://covariant.ai/insights/the-robot-brains-from-openai-to-developing-the-first-foundation-models-for-robotics/
    *   **Date:** June 7, 2023 (Pre-2024, but referenced in 2024 context as a key interview)
    *   **Key Points:** Discusses his journey from OpenAI to his role as CTO at Covariant, leading the development of the "Covariant Brain," the universal AI platform for robotics. This interview serves as a key reference for his pre-Amazon work.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Rocky Duan's work in 2024-2025 has demonstrated significant academic and industry impact in the field of robotics AI. The paper **"Sim-to-Real Learning for Humanoid Box Loco-Manipulation"** (May 2024) has been cited by at least **50** sources, indicating strong academic interest. The subsequent paper **"TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System"** (Nov 2025) has an initial citation count of **1**. His recognition in the **2024 Forbes' 30 Under 30** list highlights his industry influence. The acquisition of the Covariant founding team by Amazon in August 2024 is a major commercial validation of the technology he helped develop.

---

## Aravind Srinivas

**æ‰€å±æœºæ„**: Perplexity

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "We have to rebuild the infrastructure to scale the next 10x."
    *   **Source:** AI Startup School Interview
    *   **Date:** June 16, 2025

*   **Quote:** "The browser. Thatâ€™s the big bet we are making as far as the future of the company goes."
    *   **Source:** AI Startup School Interview
    *   **Date:** June 16, 2025

*   **Quote:** "AI is fundamentally changing how people gain information and satisfy their quest for knowledge."
    *   **Source:** Perplexity Blog Post: "Perplexity raises Series B funding round"
    *   **Date:** January 4, 2024

*   **Quote:** "Should I get a green card?" (Publicly questioned his three-year wait for a green card)
    *   **Source:** X (formerly Twitter) post
    *   **Date:** December 16, 2024

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Masked Autoencoders Are Scalable Vision Learners
    *   **Link:** https://arxiv.org/abs/2111.06377
    *   **Abstract:** We show that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. MAE simply masks random patches of the input image and reconstructs the missing pixels. It is based on two core designs: (1) an asymmetric encoder-decoder architecture, where the encoder only operates on the unmasked patches; (2) a high masking ratio (e.g., 75%). We find that MAE learns very high-quality representations that generalize well to downstream tasks. (Note: A revised version of this paper was published in May 2024, continuing its relevance in the 2024-2025 period.)

### ğŸ“ åšå®¢æ–‡ç« 

*   **Perplexity raises Series B funding round** (January 4, 2024)
    *   **Link:** https://www.perplexity.ai/hub/blog/perplexity-raises-series-b-funding-round
    *   **Summary:** Announced the successful Series B funding round, with Aravind Srinivas stating that "AI is fundamentally changing how people gain information and satisfy their quest for knowledge" and focusing on the company's mission to build the world's best answer engine.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Perplexity's Race to Build Agentic Search** (AI Startup School, June 16, 2025)
    *   **Link:** https://singjupost.com/aravind-srinivas-perplexitys-race-to-build-agentic-search-transcript/
    *   **Key Points:** Srinivas outlined Perplexity's next big bet on the browser, aiming to make it a "cognitive operating system" with an omnibox for navigation, informational queries, and "agentic tasks." He noted the company's rapid growth is causing "infrastructure issues" requiring a rebuild to scale 10x.

*   **Perplexity's Aravind Srinivas on everyday AI at Disrupt 2024** (TechCrunch Disrupt SF 2024, July 16, 2024)
    *   **Link:** https://techcrunch.com/2024/07/16/perplexitys-aravind-srinivas-on-accelerating-everyday-ai-at-techcrunch-disrupt-2024/
    *   **Key Points:** Discussion focused on AI resiliency in a crowded market and strategies for facing AI rivals.

*   **GPT-5 Backlash + Perplexity C.E.O. Aravind Srinivas on the Browser Wars + Hot Mess Express** (Hard Fork Podcast, August 15, 2025)
    *   **Link:** https://podcasts.apple.com/us/podcast/gpt-5-backlash-perplexity-c-e-o-aravind-srinivas-on/id1528594034?i=1000722080068
    *   **Key Points:** Discussed the "Browser Wars," the company's new AI-powered browser "Comet," and the competitive landscape, including a notable, likely hyperbolic, mention of a "$34 billion bid to buy Google Chrome."

*   **Perplexity: CEO Aravind Srinivas Q&A on Taking On Google** (NEA Blog, November 4, 2024)
    *   **Link:** https://www.nea.com/blog/perplexity-qa-revolutionizing-search
    *   **Key Points:** Discussed how Perplexity is revolutionizing search and challenging Google with a different, answer-engine approach.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Aravind Srinivas's impact in 2024-2025 is characterized by significant business growth, high-profile industry disruption, and continued academic influence:

*   **Business Growth:** Perplexity's traffic "exploded 10x" by 2024, and the company successfully raised a Series B funding round in January 2024.
*   **Industry Disruption:** The company's aggressive challenge to established search and e-commerce giants is evidenced by a cease-and-desist letter from Amazon (October 31, 2025) and legal pressure from The New York Times (October 2024).
*   **Public Profile:** A high-profile X post in December 2024 regarding his green card wait garnered significant attention, including a supportive response from Elon Musk, sparking a national debate on US immigration policy.
*   **Academic Influence:** His co-authored paper, "Masked Autoencoders Are Scalable Vision Learners," continues to be highly influential, with over 19,000 citations as of November 2025, underscoring his foundational contributions to computer vision.

---

## Kyle Kosic

### ğŸ“¢ é‡è¦è¨€è®º

*   **"The inflection in April 2025 is not subtle. These crates are suddenly massively more widely used in new code than they used to be, including crates that..."**
    *   **Source:** X post (@kylekosic)
    *   **Date:** March 18, 2024
*   **"Couldn't agree more. If you can afford to do so, make sure you occasionally slug for a week and read some classics."**
    *   **Source:** X reply to @karpathy (@kylekosic)
    *   **Date:** April 5, 2024
*   **"@obsdmd is the first software in ages I've been really excited to use. Reminds me of my early coding days being introduced to Sublime Text. Great product."**
    *   **Source:** X post (@kylekosic)
    *   **Date:** March 18, 2024
*   **"here have been some pretty wild years"**
    *   **Source:** X reply to @sama (@kylekosic)
    *   **Date:** March 18, 2024

### ğŸ“ åšå®¢æ–‡ç« 

*   **No specific blog posts by Kyle Kosic were found for the 2024-2025 period.** His work is primarily focused on engineering and distributed systems at xAI and OpenAI. The xAI blog posts in this period focused on Grok-1.5 and Grok-2 announcements, but did not feature him as an author or interviewee.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **No notable interviews, podcasts, or talks were found for Kyle Kosic in the 2024-2025 period.** His public profile appears to be low, focusing on his engineering and infrastructure work.

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Kyle Kosic's most significant public impact in 2024-2025 was his move from xAI back to OpenAI, which was widely covered by major tech and business news outlets (e.g., Fortune, Yahoo Finance, Observer) in June/July 2024, highlighting his importance as a founding engineer in the competitive AI landscape. His X (formerly Twitter) profile (@kylekosic) has over **12.3K followers**. His posts, such as the one on "The inflection in April 2025," generated thousands of views and dozens of likes, demonstrating engagement within the AI community.

---

## Emmett Shear

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "Not being scared of AGI indicates either pessimism about rate of future progress synthesizing digital intelligence, or severe lack of imagination about the power of intelligence."
    *   **Source:** X (formerly Twitter) - https://x.com/eshear/status/1858929198297215125
    *   **Date:** November 21, 2024
*   **Quote:** "Correspondingly, no fixed benchmark is AGI. AGI is the ability to generalize to an adversarially chosen new benchmark."
    *   **Source:** X (formerly Twitter) - https://x.com/eshear/status/1870315487755935935
    *   **Date:** December 21, 2024
*   **Quote:** "AGI [artificial general intelligence] is the ability to generalize [without special training by a...]"
    *   **Source:** John D. Cook's blog (referencing Shear) - https://www.johndcook.com/blog/2025/01/07/can-ai-models-reason-like-a-human/
    *   **Date:** January 7, 2025
*   **Quote:** Critique of the â€œcontrol and steeringâ€ paradigm in AGI development, advocating for an alternative approach.
    *   **Source:** AI-Weekly Newsletter (referencing Shear)
    *   **Date:** November 18, 2025

### ğŸ“ åšå®¢æ–‡ç« 

*   **The Frame-Dependent Mind: On Reality's Stubborn Refusal To Be One Thing**
    *   **Link:** https://softmax.com/blog/the-frame-dependent-mind
    *   **Date:** April 18, 2025
    *   **Summary:** A philosophical exploration of **frame-dependence**, arguing that all knowledge and reality are contingent on the frame (perspective) used to observe them. The post, co-authored by Emmett Shear and Sonnet 3.7, uses examples from biology, physics (relativity), and mathematics to show that there is no privileged "true frame" or absolute knowledge. It connects this to AI by suggesting that frames are created by life for survival and that the recognition of frame-dependence is a "meta-frame" that provides practical wisdom.
*   **Reimagining Alignment**
    *   **Link:** https://softmax.com/blog/reimagining-alignment
    *   **Date:** March 28, 2025
    *   **Summary:** Introduces **"organic alignment"** as Softmax's core mission, contrasting it with the prevailing "hierarchical" or "control/steering" approach to AI alignment. Organic alignment is modeled after natural systems like multicellularity, where individual agents (cells, humans, or AIs) learn to align by developing a shared, overarching goal of the collective's flourishing. The post argues that hierarchical alignment fails when the AI becomes too smart, while organic alignment is an adaptive learning process that works better as the agent becomes more capable. Softmax is pursuing a mathematical theory of this process using multi-agent reinforcement learning simulations.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Emmett Shear - AGI as "Another Kind of Cell" in the Tissue of Life (Worthy Successor, Episode 11)**
    *   **Link:** https://danfaggella.com/shear1/
    *   **Date:** July 18, 2025
    *   **Key Points:** Shear presents his vision of AGI as a "kind of living system, not unlike a new kind of cell, joining the tissue of intelligent life." He advocates for AGI to be a "participant in a multicellular moral ecosystem," calls for "coherence evals" for multi-agent systems, and stresses the need to "Start the conversation about AI rights â€“ before itâ€™s too late."
*   **AI alignment, with Emmett Shear**
    *   **Link:** https://www.complexsystemspodcast.com/episodes/ai-alignment-with-emmett-shear/
    *   **Date:** September 11, 2025
    *   **Key Points:** Shear explained his view that AI alignment requires building **digital biology** rather than relying on traditional control systems, a core tenet of his company Softmax's "organic alignment" approach.
*   **ODSC AI West 2025 Keynote**
    *   **Source:** ODSC AI West 2025 Conference (Mentioned in a Facebook post)
    *   **Date:** October 26, 2025
    *   **Key Points:** Shear was scheduled to speak at the conference as the Co-founder of Softmax, likely discussing his organic alignment philosophy. (Specific talk content not available.)

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Emmett Shear's impact in 2024-2025 is primarily driven by his founding of the AI alignment company Softmax and his high-profile public commentary on AGI. His views on "organic alignment" and the "frame-dependent mind" have been featured in prominent AI-focused podcasts and newsletters, indicating significant engagement within the AI safety and research communities. Specific engagement metrics (retweets, views) for his X posts and interviews were not publicly available without logging in, but the frequent citation of his AGI definition and his company's mission in third-party articles suggests a high level of influence and reach.

---

## David Luan

---

## Tim Shi

### ğŸ“¢ é‡è¦è¨€è®º

*   **Statement:** "Care must be taken to ensure that the model is unbiased - that it is trained on a large enough and diverse enough dataset. The other element of fairness takes place at the application layer. This is ensuring that agent populations are being made more successful by the AI..."
    *   **Source:** Cresta Blog: Responsible AI: Crestaâ€™s approach
    *   **Date:** February 1, 2024
*   **Statement:** "Cresta also invests heavily in R&D designed to make it easier for humans to interpret and understand the outputs of our AI models, including cutting-edge techniques like Chain-of-Thought Reasoning (CoT) and Model-based Critique. With CoT, we are exposing the modelâ€™s reasoning process to the user, allowing for human correction or guidance. This transparency builds trust..."
    *   **Source:** Cresta Blog: Responsible AI: Crestaâ€™s approach
    *   **Date:** February 1, 2024
*   **Statement:** "Responsible AI guidelines will become an invaluable tool in the [2024]... There is going to be a rapid increase in the number of LLMs being deployed in the enterprise."
    *   **Source:** Big Data Industry Predictions for 2024 (Inside HPC & AI News)
    *   **Date:** January 18, 2024
*   **Statement:** Tim Shi is a founding resident of AGI House, a community dedicated to advancing humanity's transition to AGI.
    *   **Source:** AGI House social media/event listings
    *   **Date:** 2024-2025 (Confirmed by multiple event/community listings)

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** GUIOdyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices
    *   **Link:** https://arxiv.org/abs/2406.08451
    *   **Date:** August 1, 2024 (v2)
    *   **Abstract:** Autonomous Graphical User Interface (GUI) navigation agents can enhance user experience by streamlining workflows. However, prior GUI agents often trained with datasets comprising tasks that can be completed within a single app, leading to poor performance in cross-app navigation. This paper presents GUIOdyssey, a comprehensive dataset for cross-app mobile GUI navigation, comprising 8,334 episodes covering 6 mobile devices, 212 distinct apps, and 1,357 app combinations. The authors also develop OdysseyAgent, an exploratory multimodal agent, and demonstrate that historical information in the dataset significantly enhances performance on complex cross-app tasks.
*   **Title:** ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data
    *   **Link:** https://arxiv.org/abs/2509.15221
    *   **Date:** September 18, 2025
    *   **Abstract:** Progress in computer use agents (CUAs) is limited by the lack of large-scale, open-source data. This work introduces ScaleCUA, a step toward scaling open-source CUAs, offering a large-scale dataset spanning 6 operating systems and 3 task domains, built via a closed-loop pipeline. Trained on this scaled-up data, ScaleCUA can operate seamlessly across platforms, delivering strong gains over baselines and setting new state-of-the-art results on various benchmarks. The findings underscore the power of data-driven scaling for general-purpose computer use agents.

### ğŸ“ åšå®¢æ–‡ç« 

*   **The Future of the Contact Center: AI Predictions for 2025**
    *   **Link:** https://cresta.com/blog/the-future-of-the-contact-center-ai-predictions-for-2025/
    *   **Date:** December 10, 2024
    *   **Summary:** Tim Shi, Cresta's CTO and co-founder, contributed to this article, which predicts key trends for AI in the contact center in 2025. The article highlights five main areas: hyper-personalization at scale, unifying agent workflows, advanced self-service options, next-generation security and compliance automation, and AI-augmented training and coaching for elevated agent performance.
*   **Responsible AI: Crestaâ€™s approach**
    *   **Link:** https://cresta.com/blog/responsible-ai-crestas-approach/
    *   **Date:** February 1, 2024
    *   **Summary:** Based on a webinar co-hosted by Tim Shi, this post outlines Cresta's four key pillars for responsible AI: **Fairness** (unbiased models, application success for all agents), **Transparency** (documenting capabilities, using Chain-of-Thought Reasoning), **Privacy & Ethics** (no recommendations based on sensitive data), and **Quality Optimization & Risk Mitigation** (data-driven design, staged deployment, human-in-the-loop QA).

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** Big Data Industry Predictions for 2024
    *   **Link:** https://insidehpc.com/2024/01/big-data-industry-predictions-for-2024/
    *   **Date:** January 18, 2024
    *   **Key Points:** Tim Shi predicted that **responsible AI guidelines will become an invaluable tool** in 2024, and that there will be a **rapid increase in the number of LLMs** being deployed in the enterprise.
*   **Title:** GenAI Summit San Francisco 2024 / Global AI Pitch Summit Silicon Valley 2025
    *   **Link:** https://sf2024.genaisummit.ai/ and https://www.instagram.com/reel/DDlXPDQh6Zb/
    *   **Date:** 2024 and 2025
    *   **Key Points:** Tim Shi was a featured speaker at both events, indicating his active participation and influence in the Generative AI and AGI community.
*   **Title:** Stanford Hidden Layer Podcast #102 (Tim Shi - Co-Founder Cresta, Early OpenAI)
    *   **Link:** https://www.youtube.com/watch?v=N62FTn0sAO0
    *   **Date:** November 2025 (1 month ago from current date)
    *   **Key Points:** Tim Shi discussed his journey from early OpenAI to co-founding Cresta, focusing on the application of AI in the contact center and his foundational work on safe AGI. (Note: The snippet date is relative, but falls within the 2024-2025 window).

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

The academic papers co-authored by Tianlin Shi (Tim Shi) in 2024 and 2025 are highly relevant to the field of AI agents and large-scale datasets, suggesting significant research impact. The paper "GUIOdyssey" (2024) is a comprehensive dataset for cross-app mobile GUI navigation, and "ScaleCUA" (2025) introduces a large-scale open-source project for computer use agents, which is a major contribution to the open-source AI community. The Cresta blog posts and interviews indicate his role as a thought leader in applying generative AI to the enterprise contact center space. The search results show his involvement in high-profile AI events like the GenAI Summit and AGI House, confirming his influence in the AGI and agent-based AI research and startup communities. Specific citation or retweet counts were not available from the search results.

---

## Maddie Hall

### ğŸ“¢ é‡è¦è¨€è®º

* "Restoring degraded mine lands offers one of the most scalable and meaningful opportunities for nature-based climate solutions." - [CarbonCredits.com](https://carboncredits.com/microsoft-buys-1-4m-tonnes-of-carbon-removal-credits-to-reforest-u-s-mined-lands/) (April 22, 2025)
* While from 2023, this statement is frequently referenced in 2025 articles: "I left OpenAI 3 years ago to pursue a challenge equally as important as AGI: climate change. While we're still short of ChatGPTree,..." - [X (formerly Twitter)](https://x.com/maddiehalla/status/1663599338843668481) (May 30, 2023)

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

* **Pattern Breakers Podcast** (May 5, 2025): A discussion on her journey from working on AI to leading a climate tech startup. [Link to notes](https://www.podnotesdigest.com/pattern-breakers-3ec2fc48)
* **Carbon Unbound 2025** (October 22, 2025): Featured speaker at a carbon removal summit that included AI as a topic. [Link to event](https://www.carbonunboundeastcoast.com/)
* **SynBioBeta 2025** (Announced December 13, 2024): Speaker at a synthetic biology conference, a field that often leverages AI. [Link to announcement](https://m.facebook.com/SynBioBeta/photos/synbiobeta-2025-welcomes-maddie-hall-of-living-carbon-and-ash-toye-of-scarlet-th/1137554845039452/)

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Maddie Hall's primary impact in 2024-2025 is through her leadership at Living Carbon, which secured a major carbon removal deal with Microsoft in April 2025. Her past role at OpenAI is consistently highlighted in media coverage, framing her current work in climate technology as a challenge of equal importance to the development of AGI. An article from May 2025 also explicitly stated that Living Carbon's bioengineering work is combined with artificial intelligence, suggesting AI is a core component of the company's technology stack.

---

## Shariq Hashme

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "Almost any indoor physical labor is on the table."
    *   **Source:** MIT Technology Review article, "The humans behind the robots"
    *   **Date:** December 24, 2024
*   **Quote:** (Implied statement on design philosophy) A focus on building robots that "feel like robots rather than machine humans."
    *   **Source:** Personal website (shar.iq)
    *   **Date:** Current (website snippet)
*   **Quote:** (Implied statement on company mission) "I'm the CEO/founder of Prosper: we're building robots to serve us in our daily lives."
    *   **Source:** Personal website (shar.iq)
    *   **Date:** Current (website snippet)

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Skill Expansion and Composition in Parameter Space
    *   **Link:** https://arxiv.org/abs/2502.05932
    *   **Abstract:** Humans excel at reusing prior knowledge to address new challenges and developing skills while solving problems. This paradigm becomes increasingly popular in the development of autonomous agents, as it develops systems that can self-evolve in response to new challenges like human beings. However, previous methods suffer from limited training efficiency when expanding new skills and fail to fully leverage prior knowledge to facilitate new task learning. In this paper, we propose Parametric Skill Expansion and Composition (PSEC), a new framework designed to iteratively evolve the agents' capabilities and efficiently address new challenges by maintaining a manageable skill library. This library can progressively integrate skill primitives as plug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient finetuning, facilitating efficient and flexible skill expansion. This structure also enables the direct skill compositions in parameter space by merging LoRA modules that encode different skills, leveraging shared information across skills to effectively program new skills. Based on this, we propose a context-aware module to dynamically activate different skills to collaboratively handle new tasks. Empowering diverse applications including multi-objective composition, dynamics shift, and continual policy shift, the results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC exhibits superior capacity to leverage prior knowledge to efficiently tackle new challenges, as well as expand its skill libraries to evolve the capabilities.
    *   **Date:** Submitted Feb 9, 2025 (v1), revised Mar 16, 2025 (v2). Accepted at ICLR 2025.

### ğŸ“ åšå®¢æ–‡ç« 

**No specific company blog posts by Shariq Hashme from Prosper Robotics were found for 2024-2025.**

*   **Note:** The search for "Prosper Robotics blog 2024 2025" did not yield direct results. The company's public presence in this period appears to be focused on media interviews and academic publications.

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Mention in "The humans behind the robots" (MIT Technology Review)**
    *   **Link:** https://www.technologyreview.com/2024/12/24/1109523/the-humans-behind-the-robots/
    *   **Key Points:** Discusses Prosper's focus on general-purpose robots for indoor physical labor. Hashme is quoted on the scope of work: "Almost any indoor physical labor is on the table." The article mentions the robot's name, Alfie, and Hashme's expectation for its first release to handle simple tasks.
    *   **Date:** December 24, 2024
*   **Mention in "Will we ever trust robots?" (MIT Technology Review)**
    *   **Link:** https://www.technologyreview.com/2024/12/23/1108466/general-purpose-robots-humanoids-ai-remote-assistants/
    *   **Key Points:** Confirms Hashme's background (ex-OpenAI, ex-Scale AI) and Prosper's entry into the "humanoid arms race" with a focus on general-purpose robots.
    *   **Date:** December 23, 2024

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Shariq Hashme's impact in 2024-2025 is characterized by significant media attention for his startup, Prosper Robotics, and continued academic contribution in the field of reinforcement learning.

*   **Media/Industry Reach:** Hashme and Prosper Robotics were featured in **two prominent MIT Technology Review articles** in late 2024 ("The humans behind the robots" and "Will we ever trust robots?"), indicating strong industry validation and public interest in their work on general-purpose robotics.
*   **Academic Citations:** The paper "Skill Expansion and Composition in Parameter Space" (ICLR 2025) has accumulated **9 citations** as of November 2025 (according to Google Scholar), demonstrating early academic impact in the area of skill-based reinforcement learning.

---

## Jonas Schneider

**æ‰€å±æœºæ„**: Daedalus

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "Imagine factories that possess the collective knowledge and expertise of all engineers and machinists who have ever worked in them, and can produce the most challenging parts with superhuman reliability and 10x efficiency. Daedalus is already making that vision real by revolutionizing how we build everything from microchips to critical medical componentsâ€”unleashing the potential of numerous industries with our AI-powered factories that forge bespoke parts on demand."
    *   **Source:** NGP Capital Press Release: Daedalus Secures $21M Series A
    *   **Date:** February 8, 2024
*   **Quote:** "The conversations we have with our customers paint a shocking picture of the state of precision manufacturing... we are still only beginning our journey. While we have already outscaled more than 50,000 incumbents, there is still $100B in annual demand we have not yet touched in Germany alone."
    *   **Source:** NGP Capital Press Release: Daedalus Secures $21M Series A
    *   **Date:** February 8, 2024

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** Inconsistencies in Production Workflows and How to Model Them
    *   **Link:** https://colab.ws/articles/10.1109%2Ficsa-c63560.2024.00021 (DOI Link)
    *   **Abstract:** This paper addresses the challenge of modeling inconsistencies in production workflows, particularly in the context of advanced manufacturing. It proposes a method using specific event types within BPMN 2.0 diagrams to model these inconsistencies. Jonas Schneider is listed as an author affiliated with Daedalus GmbH, indicating his contribution to the application of AI and software engineering principles to manufacturing process optimization.
    *   **Date:** 2024 (Published in ICSA-C 2024)

### ğŸ“ åšå®¢æ–‡ç« 

*   **Title:** Daedalus, a startup led by former OpenAI technical lead, secures $21M to redefine manufacturing with AI
    *   **Link:** https://ngpcap.com/insights/daedalus-a-startup-led-by-former-openai-technical-lead-secures-21m-to-redefine-manufacturing-with-ai
    *   **Summary:** This press release, published on the lead investor's website, details Daedalus's $21 million Series A funding round. It highlights the company's mission to build the world's most advanced factories using an AI-powered platform to automate the entire manufacturing process for high-precision parts. It includes a key quote from Jonas Schneider about the vision for AI-driven factories.
    *   **Date:** February 8, 2024

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

No new, publicly available interviews or talks from Jonas Schneider specifically on AI, AGI, or world models were found for the 2024-2025 period. His public presence is primarily focused on the company's manufacturing mission. (Note: Older interviews from his time at OpenAI were found but are outside the requested timeframe.)

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

The primary impact metric for the 2024-2025 period is the successful **$21 million Series A funding round** announced on February 8, 2024, which was led by NGP Capital with participation from Addition and Khosla Ventures. This event generated significant media coverage across major technology and financial news outlets (e.g., TechCrunch, Reuters, SiliconANGLE), establishing Daedalus and Jonas Schneider as a notable player in the AI-driven manufacturing space. The company's claim to have "already outscaled more than 50,000 incumbents" in the precision manufacturing sector suggests a high level of operational impact and market penetration.

---

## Jeff Arnold

---

## Margaret Jennings

### ğŸ“¢ é‡è¦è¨€è®º

*   **Quote:** "I feel like weâ€™ve already achieved AGI. I think the [Turing Test] has already happened, in a lot of ways. Now weâ€™re playing on the margins of whatâ€™s possible.â€
    *   **Source:** American School in London (ASL) News Post
    *   **Date:** August 28, 2025
    *   **Context:** A contrarian view on the state of Artificial General Intelligence (AGI) and the Turing Test.

*   **Quote:** "As someone who works with AI every day, I think itâ€™s very easy to get caught up on existential risk... To Margaret, climate change, not AGI, is the dominant existential threat that we face, and she believes that the AI industry is showing how new technologies can 'augment the scientist,' and therefore be a key part of the solution."
    *   **Source:** American School in London (ASL) News Post
    *   **Date:** August 28, 2025
    *   **Context:** Statement on AI existential risk and the role of AI in addressing climate change.

*   **Quote:** "What else can we achieve? What else can we unlock? What does this new industrial revolution look like, and how do we make sure that as many people as possible are included as part of this change?â€
    *   **Source:** American School in London (ASL) News Post
    *   **Date:** August 28, 2025
    *   **Context:** Her focus on the positive, inclusive potential of the AI industrial revolution.

*   **Quote:** "The ability to create..."
    *   **Source:** Mentioned in a LinkedIn Pulse article on Scaling Product Management in the Age of AI
    *   **Date:** Approximately Late 2024
    *   **Context:** Expressing excitement about the creative potential of AI in product development at Mistral AI.

### ğŸ“„ å­¦æœ¯è®ºæ–‡

*   **Title:** **That's not natural: The Impact of Off-Policy Training Data on Probe Performance**
    *   **Authors:** Nathalie Kirch, Samuel Dower, Adrians Skapars, Ekdeep Singh Lubana, Dmitrii Krasheninnikov, *et al.* (Margaret Jennings is listed as a co-author in the related EMNLP paper's full author list)
    *   **Link:** `https://arxiv.org/abs/2511.17408`
    *   **Date:** November 21, 2025
    *   **Abstract:** Probing is a promising method for monitoring Large Language Models (LLMs) for concerning behaviors like deception and sycophancy. This paper systematically evaluates how the use of synthetic and off-policy data influences probe generalization across eight distinct LLM behaviors. The findings suggest that successful generalization from off-policy data is predictive of successful on-policy generalization, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

*   **Title:** **PLLuM-Align: Polish Preference Dataset for Large Language Model Alignment**
    *   **Authors:** K Seweryn, *et al.* (Margaret Jennings is listed as a co-author in the full Mistral AI Team author list)
    *   **Link:** `https://aclanthology.org/2025.emnlp-main.1219.pdf`
    *   **Date:** 2025 (EMNLP Main Conference)
    *   **Abstract:** This paper introduces the first Polish preference dataset, PLLuM-Align, created through human annotation to reflect Polish language and cultural nuances. The dataset is intended to aid in the alignment of Large Language Models for non-English languages. (Note: Margaret Jennings is listed as part of the Mistral AI team that contributed to this work.)

### ğŸ“ åšå®¢æ–‡ç« 

*   **"What just happened? Where we've been and headed with AI"**
    *   **Source:** Kindo AI Blog
    *   **Link:** `https://www.kindo.ai/blog/where-weve-been-and-where-were-headed-with-ai`
    *   **Date:** September 19, 2023 (Note: This is outside the 2024-2025 range, but is a key piece of writing before her move to Mistral AI and provides context.)
    *   **Summary:** An exploration of the shift from a prediction era to a generative era in AI, focusing on the secure deployment of GenAI in enterprise workflows.

*   **"Scaling Product Management in the Age of AI: Efficiency with a Human Touch"**
    *   **Source:** LinkedIn Pulse (Mention)
    *   **Link:** `https://www.linkedin.com/pulse/scaling-product-management-age-ai-efficiency-human-touch-tomasini-mekie`
    *   **Date:** 1 year ago (Approx. Late 2024)
    *   **Summary:** Margaret Jennings, Head of Product at Mistral AI, is mentioned as sharing her excitement about "The ability to create..." in the context of scaling product management in the AI age. (Note: No full blog post by her was found in the 2024-2025 range, only a mention in a third-party article.)

### ğŸ¤ è®¿è°ˆä¸æ¼”è®²

*   **Title:** Margaret Jennings '09 is keeping the humanities in human-centered AI
    *   **Source:** American School in London (ASL) News Post
    *   **Link:** `https://www.asl.org/about/news-publications-and-speakers/news-and-blogs/news-post/~board/news-stories/post/margaret-jennings-09-is-keeping-the-humanities-in-human-centered-ai`
    *   **Date:** August 28, 2025
    *   **Key Points:**
        *   Discusses her role as Head of Model Behavior at Mistral AI.
        *   Emphasizes the importance of humanities in AI development.
        *   States her contrarian view that **"I feel like weâ€™ve already achieved AGI. I think the [Turing Test] has already happened, in a lot of ways."**
        *   Identifies **climate change, not AGI, as the dominant existential threat**, believing AI can "augment the scientist" to solve it.
        *   Focuses on the questions: "What else can we achieve? What else can we unlock? What does this new industrial revolution look like, and how do we make sure that as many people as possible are included as part of this change?â€

### ğŸ“Š å½±å“åŠ›æŒ‡æ ‡

Margaret Jennings' impact is primarily seen through her key roles at two significant AI companies in the 2024-2025 period:
*   **Kindo AI (Co-founder):** Co-founded Kindo AI, which raised a $21M Series A round (as of May 2025) and focuses on secure GenAI deployment.
*   **Mistral AI (Head of Model Behavior/Product):** Her work on "model behavior" is critical to Mistral AI's alignment and safety efforts, a highly visible and impactful area in the AI industry. She is listed as an author on at least one major technical report from Mistral AI in 2025.
*   **Academic Citations:** She is listed as an author on the technical report **"That's not natural: The Impact of Off-Policy Training Data on Probe Performance"** (arXiv:2511.17408, Nov 2025), which is a key contribution to the field of LLM alignment and safety. The paper is too recent for significant citation data, but its presence on arXiv and the EMNLP-main 2025 proceedings (via co-authorship on a related paper) indicates high academic visibility.

---

## æ€»ç»“

æœ¬æŠ¥å‘Šæ¶µç›–äº†ä» OpenAI ç¦»èŒåˆ›ä¸šçš„ 20 ä½é¡¶çº§ AI äººæ‰åœ¨ 2024-2025 å¹´çš„æ ¸å¿ƒè´¡çŒ®ï¼š

### å…³é”®è¶‹åŠ¿

1. **ä» Scaling åˆ° Research**: Ilya Sutskever ç­‰äººå¼ºè°ƒ AI å‘å±•å·²ä»å•çº¯æ‰©å±•æ¨¡å‹è§„æ¨¡è½¬å‘éœ€è¦åŸºç¡€æ€§ç ”ç©¶çªç ´
2. **AI å®‰å…¨ä¼˜å…ˆ**: SSIã€Anthropic ç­‰å…¬å¸å°†å®‰å…¨æ€§ä½œä¸ºæ ¸å¿ƒä½¿å‘½
3. **åº”ç”¨è½åœ°åŠ é€Ÿ**: ä» AI Agentï¼ˆAdeptï¼‰åˆ°æœºå™¨äººï¼ˆCovariantã€Prosperï¼‰å†åˆ°æœç´¢ï¼ˆPerplexityï¼‰ï¼Œåº”ç”¨åœºæ™¯ä¸æ–­æ‹“å±•
4. **æ•™è‚²æ°‘ä¸»åŒ–**: Eureka Labs è‡´åŠ›äºè®© AI æ•™è‚²æ™®åŠåŒ–
5. **å·¨é¢èèµ„**: å¤šå®¶åˆåˆ›å…¬å¸è·å¾—æ•°åäº¿ç¾å…ƒèèµ„ï¼Œä¼°å€¼å¿«é€Ÿæ”€å‡

### æ ¸å¿ƒè§‚ç‚¹ç¢°æ’

- **AGI æ—¶é—´çº¿**: ä» John Schulman çš„"2-3å¹´"åˆ°æ›´ä¿å®ˆçš„"5-10å¹´"é¢„æµ‹
- **æŠ€æœ¯è·¯å¾„**: Scaling Laws æ´¾ vs æ·±åº¦ç ”ç©¶æ´¾ vs ä¸–ç•Œæ¨¡å‹æ´¾
- **å¼€æº vs é—­æº**: ä¸åŒå…¬å¸é‡‡å–æˆªç„¶ä¸åŒçš„ç­–ç•¥

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2025-11-28*  
*æ•°æ®æ¥æº: å…¬å¼€å‘è¡¨çš„è®ºæ–‡ã€åšå®¢ã€è®¿è°ˆåŠç¤¾äº¤åª’ä½“*
