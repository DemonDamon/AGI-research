# The AI alignment problem: why it is hard, and where to start

**类型**: 论文 (Paper)

**链接**: [https://intelligence.org/files/AlignmentHardStart.pdf](https://intelligence.org/files/AlignmentHardStart.pdf)

## 摘要

An influential paper by Eliezer Yudkowsky, a key figure in AI safety, discussing the fundamental difficulties of the AI alignment problem and suggesting initial approaches.

## 下载

请访问上述链接查看完整论文。
