# A Survey on Multimodal Benchmarks: In the Era of Large AI Models

**类型**: 论文 (Paper)

**链接**: [https://arxiv.org/abs/2409.18142](https://arxiv.org/abs/2409.18142)

## 摘要

A systematic review of 211 benchmarks used for evaluating Multimodal Large Language Models (MLLMs) across four core domains: understanding, reasoning, generation, and application.

## 下载

请访问上述链接查看完整论文。
